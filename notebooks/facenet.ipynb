{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014e3f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_directory' from 'PIL._util' (/Users/hinsun/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/PIL/_util.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfacenet_pytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MTCNN, InceptionResnetV1\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/facenet_pytorch/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minception_resnet_v1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InceptionResnetV1\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmtcnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MTCNN, PNet, RNet, ONet, prewhiten, fixed_image_standardization\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdetect_face\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_face\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m training\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/facenet_pytorch/models/mtcnn.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdetect_face\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m detect_face, extract_face\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPNet\u001b[39;00m(nn.Module):\n\u001b[32m     10\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"MTCNN PNet.\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m    Keyword Arguments:\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m        pretrained {bool} -- Whether or not to load saved pretrained weights (default: {True})\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/facenet_pytorch/models/utils/detect_face.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interpolate\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mboxes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m batched_nms\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/torchvision/__init__.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodulefinder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/torchvision/datasets/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_optical_flow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_stereo_matching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     CarlaStereo,\n\u001b[32m      4\u001b[39m     CREStereo,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     SintelStereo,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcaltech\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Caltech101, Caltech256\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/torchvision/datasets/_optical_flow.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _read_png_16\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _read_pfm, verify_str_arg\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisionDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/torchvision/io/__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterator\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_load_gpu_decoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_GPU_VIDEO_DECODER\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/torchvision/utils.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageColor, ImageDraw, ImageFont\n\u001b[32m     13\u001b[39m __all__ = [\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmake_grid\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msave_image\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mflow_to_image\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m ]\n\u001b[32m     23\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_grid\u001b[39m(\n\u001b[32m     25\u001b[39m     tensor: Union[torch.Tensor, List[torch.Tensor]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     pad_value: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m,\n\u001b[32m     32\u001b[39m ) -> torch.Tensor:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/PIL/ImageFont.py:40\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BinaryIO\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_directory, is_path\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLayout\u001b[39;00m(IntEnum):\n\u001b[32m     44\u001b[39m     BASIC = \u001b[32m0\u001b[39m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'is_directory' from 'PIL._util' (/Users/hinsun/Workspace/Software/Agrismart/.venv/lib/python3.12/site-packages/PIL/_util.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from typing import Optional, Tuple, List\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the MTCNN module for face detection and the InceptionResnetV1 module for face embedding.\n",
    "mtcnn = MTCNN(image_size=160, keep_all=True)\n",
    "resnet = InceptionResnetV1(pretrained=\"vggface2\").eval()\n",
    "\n",
    "\n",
    "def convert_tensor_to_image(tensor: torch.Tensor):\n",
    "    image = tensor.permute(1, 2, 0).detach().numpy()\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    image = (image * 255).astype(\"uint8\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def embedding_face(image) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "    faces, probs = mtcnn(image, return_prob=True)\n",
    "    if faces is None or len(faces) == 0:\n",
    "        return None, None\n",
    "\n",
    "    embedding = resnet(faces[0].unsqueeze(0))\n",
    "    return embedding, faces[0]\n",
    "\n",
    "\n",
    "def find_most(target: str, candidates: List[str]):\n",
    "    embedding_target, _ = embedding_face(cv2.imread(target))\n",
    "    if embedding_target is None:\n",
    "        raise ValueError(\"Target face embedding could not be computed.\")\n",
    "\n",
    "    embedding_candidates = []\n",
    "    for candidate in candidates:\n",
    "        embedding_candidate, _ = embedding_face(cv2.imread(candidate))\n",
    "        if embedding_candidate is not None:\n",
    "            embedding_candidates.append(embedding_candidate)\n",
    "\n",
    "    return find_most_similar(embedding_target, embedding_candidates)\n",
    "\n",
    "\n",
    "def find_most_similar(embedding: torch.Tensor, candidates: List[torch.Tensor]):\n",
    "    similarities = []\n",
    "\n",
    "    for candidate in candidates:\n",
    "        similarity = torch.nn.functional.cosine_similarity(embedding, candidate).item()\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    return similarities\n",
    "\n",
    "\n",
    "def plot_face_and_similarities(\n",
    "    faces: List[str],\n",
    "    similarities: List[float],\n",
    "):\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for i, (face, similarity) in enumerate(zip(faces, similarities)):\n",
    "        row = i // 5\n",
    "        col = i % 5\n",
    "\n",
    "        image = cv2.imread(face, cv2.IMREAD_COLOR)\n",
    "        axs[row, col].imshow(image)\n",
    "        axs[row, col].axis(\"off\")\n",
    "        axs[row, col].set_title(f\"Similarity: {similarity:.2f}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    root_directory = os.getcwd()\n",
    "    me_directory = os.path.join(root_directory, \"datasets\", \"faces\", \"me\")\n",
    "    ginting_directory = os.path.join(root_directory, \"datasets\", \"faces\", \"ginting\")\n",
    "    momota_directory = os.path.join(root_directory, \"datasets\", \"faces\", \"momota\")\n",
    "\n",
    "    if (\n",
    "        not os.path.exists(me_directory)\n",
    "        or not os.path.exists(ginting_directory)\n",
    "        or not os.path.exists(momota_directory)\n",
    "    ):\n",
    "        print(\"One or more directories do not exist. Please check the paths.\")\n",
    "        return\n",
    "\n",
    "    # Collects all images from the directories\n",
    "    target_image = os.path.join(me_directory, os.listdir(me_directory)[0])\n",
    "    print(target_image)\n",
    "\n",
    "    candidates = []\n",
    "    for directory in [ginting_directory, momota_directory, me_directory]:\n",
    "        candidates.extend([os.path.join(directory, f) for f in os.listdir(directory) if f.endswith((\".jpg\", \".png\"))])\n",
    "\n",
    "    similarities = find_most(target_image, candidates)\n",
    "    plot_face_and_similarities(\n",
    "        faces=candidates,\n",
    "        similarities=similarities,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
